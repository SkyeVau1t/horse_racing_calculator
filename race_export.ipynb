{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e482b51e",
   "metadata": {},
   "source": [
    "## Import PDF and Convert to TXT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "a34a67e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REPO_ROOT: c:\\Users\\tnaut\\horse_racing_calculator\n",
      "DATA_DIR: c:\\Users\\tnaut\\horse_racing_calculator\\race_data\n",
      "PDF_PATH: c:\\Users\\tnaut\\horse_racing_calculator\\race_data\\OP--12-26-2025.pdf\n",
      "TXT_PATH: c:\\Users\\tnaut\\horse_racing_calculator\\race_data\\OP--12-26-2025.txt\n",
      "Temp PDF copy created: C:\\Users\\tnaut\\AppData\\Local\\Temp\\horse_racing_tmp\\OP--12-26-2025.pdf\n",
      "TXT written to: c:\\Users\\tnaut\\horse_racing_calculator\\race_data\\OP--12-26-2025.txt\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import shutil\n",
    "from pypdf import PdfReader\n",
    "import re\n",
    "import unicodedata\n",
    "from collections import Counter\n",
    "from __future__ import annotations\n",
    "from typing import Dict\n",
    "import pandas as pd\n",
    "\n",
    "# ----------------------------\n",
    "# 1) Resolve repo + data paths\n",
    "# ----------------------------\n",
    "REPO_ROOT = Path.cwd()  # assumes notebook opened from repo root\n",
    "DATA_DIR = REPO_ROOT / \"race_data\"\n",
    "\n",
    "PDF_NAME = \"OP--12-26-2025.pdf\"\n",
    "PDF_PATH = DATA_DIR / PDF_NAME\n",
    "TXT_PATH = DATA_DIR / PDF_PATH.with_suffix(\".txt\").name  # OP--12-26-2025.txt\n",
    "\n",
    "print(\"REPO_ROOT:\", REPO_ROOT)\n",
    "print(\"DATA_DIR:\", DATA_DIR)\n",
    "print(\"PDF_PATH:\", PDF_PATH)\n",
    "print(\"TXT_PATH:\", TXT_PATH)\n",
    "\n",
    "if not PDF_PATH.exists():\n",
    "    raise FileNotFoundError(f\"Could not find PDF at: {PDF_PATH}\")\n",
    "\n",
    "# -----------------------------------------\n",
    "# 2) Permission workaround: temp PDF copy\n",
    "#    (avoids file-in-use locks / OneDrive)\n",
    "# -----------------------------------------\n",
    "TEMP_DIR = Path(os.environ.get(\"TEMP\", str(REPO_ROOT))) / \"horse_racing_tmp\"\n",
    "TEMP_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "TEMP_PDF_PATH = TEMP_DIR / PDF_NAME\n",
    "\n",
    "# Copy PDF to temp to avoid permission/file-lock issues\n",
    "shutil.copy2(PDF_PATH, TEMP_PDF_PATH)\n",
    "print(\"Temp PDF copy created:\", TEMP_PDF_PATH)\n",
    "\n",
    "# -----------------------------------------\n",
    "# 3) Extract text from temp PDF -> write TXT\n",
    "#    directly to your data location\n",
    "# -----------------------------------------\n",
    "reader = PdfReader(str(TEMP_PDF_PATH))\n",
    "\n",
    "DATA_DIR.mkdir(parents=True, exist_ok=True)  # ensure exists\n",
    "with TXT_PATH.open(\"w\", encoding=\"utf-8\") as out:\n",
    "    for i, page in enumerate(reader.pages, start=1):\n",
    "        text = page.extract_text() or \"\"\n",
    "        out.write(f\"\\n\\n--- Page {i} ---\\n\")\n",
    "        out.write(text)\n",
    "\n",
    "print(f\"TXT written to: {TXT_PATH}\")\n",
    "\n",
    "# -----------------------------------------\n",
    "# 4) Clean up temp PDF\n",
    "# -----------------------------------------\n",
    "\n",
    "_ZERO_WIDTH = re.compile(r\"[\\u200B-\\u200F\\u202A-\\u202E\\u2060\\uFEFF]\")\n",
    "\n",
    "def normalize_pdf_text(s: str) -> str:\n",
    "    \"\"\"\n",
    "    Make extracted PDF text more matchable:\n",
    "    - NFKC: folds compatibility forms\n",
    "    - Removes common zero-width / bidi controls\n",
    "    \"\"\"\n",
    "    s = unicodedata.normalize(\"NFKC\", s)\n",
    "    s = _ZERO_WIDTH.sub(\"\", s)\n",
    "    return s\n",
    "\n",
    "\n",
    "def _replace_all(s: str, mapping: Dict[str, str]) -> str:\n",
    "    \"\"\"\n",
    "    One-pass replacement using a regex alternation.\n",
    "    Longest keys first to avoid partial matches.\n",
    "    \"\"\"\n",
    "    if not mapping:\n",
    "        return s\n",
    "\n",
    "    keys = sorted(mapping.keys(), key=len, reverse=True)\n",
    "    pattern = re.compile(\"|\".join(re.escape(k) for k in keys))\n",
    "    return pattern.sub(lambda m: mapping[m.group(0)], s)\n",
    "\n",
    "\n",
    "# --- Your tiered converters ---\n",
    "def convert_3seq_glyphs(s: str, map3: Dict[str, str]) -> str:\n",
    "    return _replace_all(s, map3)\n",
    "\n",
    "def convert_2seq_glyphs(s: str, map2: Dict[str, str]) -> str:\n",
    "    return _replace_all(s, map2)\n",
    "\n",
    "def convert_1glyphs(s: str, map1: Dict[str, str]) -> str:\n",
    "    return _replace_all(s, map1)\n",
    "\n",
    "def convert_0glyphs(s: str, map0: Dict[str, str]) -> str:\n",
    "    return _replace_all(s, map0)\n",
    "\n",
    "def convert_Cglyphs(s: str, mapC: Dict[str, str]) -> str:\n",
    "    return _replace_all(s, mapC)\n",
    "\n",
    "def convert_all_glyphs(s: str, map3: Dict[str, str], map2: Dict[str, str], map1: Dict[str, str], map0: Dict[str, str], mapC: Dict[str, str]) -> str:\n",
    "    s = normalize_pdf_text(s)\n",
    "    s = convert_3seq_glyphs(s, map3)\n",
    "    s = convert_2seq_glyphs(s, map2)\n",
    "    s = convert_1glyphs(s, map1)\n",
    "    s = convert_0glyphs(s, map0)\n",
    "    s = convert_Cglyphs(s, mapC)\n",
    "    return s\n",
    "\n",
    "map3 = {\n",
    "    '¦¦õ': '^11.25 ',\n",
    "    '¦¦ô': '^11.50 ',\n",
    "    '¦¦ö': '^11.75 ',\n",
    "    '¦§õ': '^12.25 ',\n",
    "    '¦§ô': '^12.50 ',\n",
    "    '¦§ö': '^12.75 ',\n",
    "    '¦ ̈õ': '^13.25 ',\n",
    "    '¦ ̈ô': '^13.50 ',\n",
    "    '¦ ̈ö': '^13.75 ',\n",
    "    '¦©õ': '^14.25 ',\n",
    "    '¦©ô': '^14.50 ',\n",
    "    '¦©ö': '^14.75 ',\n",
    "    '¦aõ': '^15.25 ',\n",
    "    '¦aô': '^15.50 ',\n",
    "    '¦aö': '^15.75 ',\n",
    "    '¦«õ': '^16.25 ',\n",
    "    '¦«ô': '^16.50 ',\n",
    "    '¦«ö': '^16.75 ',\n",
    "    '¦¬õ': '^17.25 ',\n",
    "    '¦¬ô': '^17.50 ',\n",
    "    '¦¬ö': '^17.75 ',\n",
    "    '¦¤õ': '^18.25 ',\n",
    "    '¦¤ô': '^18.50 ',\n",
    "    '¦¤ö': '^18.75 ',\n",
    "    '¦®õ': '^19.25 ',\n",
    "    '¦®ô': '^19.50 ',\n",
    "    '¦®ö': '^19.75 ',\n",
    "    '§¥õ': '^20.25 ',\n",
    "    '§¥ô': '^20.50 ',\n",
    "    '§¥ö': '^20.75 ',\n",
    "    '§¦õ': '^21.25 ',\n",
    "    '§¦ô': '^21.50 ',\n",
    "    '§¦ö': '^21.75 ',\n",
    "    '§§õ': '^22.25 ',\n",
    "    '§§ô': '^22.50 ',\n",
    "    '§§ö': '^22.75 ',\n",
    "    '§ ̈õ': '^23.25 ',\n",
    "    '§ ̈ô': '^23.50 ',\n",
    "    '§ ̈ö': '^23.75 ',\n",
    "    '§©õ': '^24.25 ',\n",
    "    '§©ô': '^24.50 ',\n",
    "    '§©ö': '^24.75 ',\n",
    "    '§aõ': '^25.25 ',\n",
    "    '§aô': '^25.50 ',\n",
    "    '§aö': '^25.75 ',\n",
    "    '§«õ': '^26.25 ',\n",
    "    '§«ô': '^26.50 ',\n",
    "    '§«ö': '^26.75 ',\n",
    "    '§¬õ': '^27.25 ',\n",
    "    '§¬ô': '^27.50 ',\n",
    "    '§¬ö': '^27.75 ',\n",
    "    '§¤õ': '^28.25 ',\n",
    "    '§¤ô': '^28.50 ',\n",
    "    '§¤ö': '^28.75 ',\n",
    "    '§®õ': '^29.25 ',\n",
    "    '§®ô': '^29.50 ',\n",
    "    '§®ö': '^29.75 ',\n",
    "    ' ̈¥õ': '^30.25 ',\n",
    "    ' ̈¥ô': '^30.50 ',\n",
    "    ' ̈¥ö': '^30.75 ',\n",
    "    ' ̈¦õ': '^31.25 ',\n",
    "    ' ̈¦ô': '^31.50 ',\n",
    "    ' ̈¦ö': '^31.75 ',\n",
    "    ' ̈§õ': '^32.25 ',\n",
    "    ' ̈§ô': '^32.50 ',\n",
    "    ' ̈§ö': '^32.75 ',\n",
    "    ' ̈ ̈õ': '^33.25 ',\n",
    "    ' ̈ ̈ô': '^33.50 ',\n",
    "    ' ̈ ̈ö': '^33.75 ',\n",
    "    ' ̈©õ': '^34.25 ',\n",
    "    ' ̈©ô': '^34.50 ',\n",
    "    ' ̈©ö': '^34.75 ',\n",
    "    ' ̈aõ': '^35.25 ',\n",
    "    ' ̈aô': '^35.50 ',\n",
    "    ' ̈aö': '^35.75 ',\n",
    "    ' ̈«õ': '^36.25 ',\n",
    "    ' ̈«ô': '^36.50 ',\n",
    "    ' ̈«ö': '^36.75 ',\n",
    "    ' ̈¬õ': '^37.25 ',\n",
    "    ' ̈¬ô': '^37.50 ',\n",
    "    ' ̈¬ö': '^37.75 ',\n",
    "    ' ̈¤õ': '^38.25 ',\n",
    "    ' ̈¤ô': '^38.50 ',\n",
    "    ' ̈¤ö': '^38.75 ',\n",
    "    ' ̈®õ': '^39.25 ',\n",
    "    ' ̈®ô': '^39.50 ',\n",
    "    ' ̈®ö': '^39.75 ',\n",
    "    '©¥õ': '^40.25 ',\n",
    "    '©¥ô': '^40.50 ',\n",
    "    '©¥ö': '^40.75 ',\n",
    "    '©¦õ': '^41.25 ',\n",
    "    '©¦ô': '^41.50 ',\n",
    "    '©¦ö': '^41.75 ',\n",
    "    '©§õ': '^42.25 ',\n",
    "    '©§ô': '^42.50 ',\n",
    "    '©§ö': '^42.75 ',\n",
    "    '© ̈õ': '^43.25 ',\n",
    "    '© ̈ô': '^43.50 ',\n",
    "    '© ̈ö': '^43.75 ',\n",
    "    '©©õ': '^44.25 ',\n",
    "    '©©ô': '^44.50 ',\n",
    "    '©©ö': '^44.75 ',\n",
    "    '©aõ': '^45.25 ',\n",
    "    '©aô': '^45.50 ',\n",
    "    '©aö': '^45.75 ',\n",
    "    '©«õ': '^46.25 ',\n",
    "    '©«ô': '^46.50 ',\n",
    "    '©«ö': '^46.75 ',\n",
    "    '©¬õ': '^47.25 ',\n",
    "    '©¬ô': '^47.50 ',\n",
    "    '©¬ö': '^47.75 ',\n",
    "    '©¤õ': '^48.25 ',\n",
    "    '©¤ô': '^48.50 ',\n",
    "    '©¤ö': '^48.75 ',\n",
    "    '©®õ': '^49.25 ',\n",
    "    '©®ô': '^49.50 ',\n",
    "    '©®ö': '^49.75 ',\n",
    "    'a¥õ': '^50.25 ',\n",
    "    'a¥ô': '^50.50 ',\n",
    "    'a¥ö': '^50.75 ',\n",
    "    'a¦õ': '^51.25 ',\n",
    "    'a¦ô': '^51.50 ',\n",
    "    'a¦ö': '^51.75 ',\n",
    "    'a§õ': '^52.25 ',\n",
    "    'a§ô': '^52.50 ',\n",
    "    'a§ö': '^52.75 ',\n",
    "    'a ̈õ': '^53.25 ',\n",
    "    'a ̈ô': '^53.50 ',\n",
    "    'a ̈ö': '^53.75 ',\n",
    "    'a©õ': '^54.25 ',\n",
    "    'a©ô': '^54.50 ',\n",
    "    'a©ö': '^54.75 ',\n",
    "    'aaõ': '^55.25 ',\n",
    "    'aaô': '^55.50 ',\n",
    "    'aaö': '^55.75 ',\n",
    "    'a«õ': '^56.25 ',\n",
    "    'a«ô': '^56.50 ',\n",
    "    'a«ö': '^56.75 ',\n",
    "    'a¬õ': '^57.25 ',\n",
    "    'a¬ô': '^57.50 ',\n",
    "    'a¬ö': '^57.75 ',\n",
    "    'a¤õ': '^58.25 ',\n",
    "    'a¤ô': '^58.50 ',\n",
    "    'a¤ö': '^58.75 ',\n",
    "    'a®õ': '^59.25 ',\n",
    "    'a®ô': '^59.50 ',\n",
    "    'a®ö': '^59.75 ',\n",
    "    '«¥õ': '^60.25 ',\n",
    "    '«¥ô': '^60.50 ',\n",
    "    '«¥ö': '^60.75 ',\n",
    "    '«¦õ': '^61.25 ',\n",
    "    '«¦ô': '^61.50 ',\n",
    "    '«¦ö': '^61.75 ',\n",
    "    '«§õ': '^62.25 ',\n",
    "    '«§ô': '^62.50 ',\n",
    "    '«§ö': '^62.75 ',\n",
    "    '« ̈õ': '^63.25 ',\n",
    "    '« ̈ô': '^63.50 ',\n",
    "    '« ̈ö': '^63.75 ',\n",
    "    '«©õ': '^64.25 ',\n",
    "    '«©ô': '^64.50 ',\n",
    "    '«©ö': '^64.75 ',\n",
    "    '«aõ': '^65.25 ',\n",
    "    '«aô': '^65.50 ',\n",
    "    '«aö': '^65.75 ',\n",
    "    '««õ': '^66.25 ',\n",
    "    '««ô': '^66.50 ',\n",
    "    '««ö': '^66.75 ',\n",
    "    '«¬õ': '^67.25 ',\n",
    "    '«¬ô': '^67.50 ',\n",
    "    '«¬ö': '^67.75 ',\n",
    "    '«¤õ': '^68.25 ',\n",
    "    '«¤ô': '^68.50 ',\n",
    "    '«¤ö': '^68.75 ',\n",
    "    '«®õ': '^69.25 ',\n",
    "    '«®ô': '^69.50 ',\n",
    "    '«®ö': '^69.75 ',\n",
    "    '¬¥õ': '^70.25 ',\n",
    "    '¬¥ô': '^70.50 ',\n",
    "    '¬¥ö': '^70.75 ',\n",
    "    '¬¦õ': '^71.25 ',\n",
    "    '¬¦ô': '^71.50 ',\n",
    "    '¬¦ö': '^71.75 ',\n",
    "    '¬§õ': '^72.25 ',\n",
    "    '¬§ô': '^72.50 ',\n",
    "    '¬§ö': '^72.75 ',\n",
    "    '¬ ̈õ': '^73.25 ',\n",
    "    '¬ ̈ô': '^73.50 ',\n",
    "    '¬ ̈ö': '^73.75 ',\n",
    "    '¬©õ': '^74.25 ',\n",
    "    '¬©ô': '^74.50 ',\n",
    "    '¬©ö': '^74.75 ',\n",
    "    '¬aõ': '^75.25 ',\n",
    "    '¬aô': '^75.50 ',\n",
    "    '¬aö': '^75.75 ',\n",
    "    '¬«õ': '^76.25 ',\n",
    "    '¬«ô': '^76.50 ',\n",
    "    '¬«ö': '^76.75 ',\n",
    "    '¬¬õ': '^77.25 ',\n",
    "    '¬¬ô': '^77.50 ',\n",
    "    '¬¬ö': '^77.75 ',\n",
    "    '¬¤õ': '^78.25 ',\n",
    "    '¬¤ô': '^78.50 ',\n",
    "    '¬¤ö': '^78.75 ',\n",
    "    '¬®õ': '^79.25 ',\n",
    "    '¬®ô': '^79.50 ',\n",
    "    '¬®ö': '^79.75 ',\n",
    "    '¤¥õ': '^80.25 ',\n",
    "    '¤¥ô': '^80.50 ',\n",
    "    '¤¥ö': '^80.75 ',\n",
    "    '¤¦õ': '^81.25 ',\n",
    "    '¤¦ô': '^81.50 ',\n",
    "    '¤¦ö': '^81.75 ',\n",
    "    '¤§õ': '^82.25 ',\n",
    "    '¤§ô': '^82.50 ',\n",
    "    '¤§ö': '^82.75 ',\n",
    "    '¤ ̈õ': '^83.25 ',\n",
    "    '¤ ̈ô': '^83.50 ',\n",
    "    '¤ ̈ö': '^83.75 ',\n",
    "    '¤©õ': '^84.25 ',\n",
    "    '¤©ô': '^84.50 ',\n",
    "    '¤©ö': '^84.75 ',\n",
    "    '¤aõ': '^85.25 ',\n",
    "    '¤aô': '^85.50 ',\n",
    "    '¤aö': '^85.75 ',\n",
    "    '¤«õ': '^86.25 ',\n",
    "    '¤«ô': '^86.50 ',\n",
    "    '¤«ö': '^86.75 ',\n",
    "    '¤¬õ': '^87.25 ',\n",
    "    '¤¬ô': '^87.50 ',\n",
    "    '¤¬ö': '^87.75 ',\n",
    "    '¤¤õ': '^88.25 ',\n",
    "    '¤¤ô': '^88.50 ',\n",
    "    '¤¤ö': '^88.75 ',\n",
    "    '¤®õ': '^89.25 ',\n",
    "    '¤®ô': '^89.50 ',\n",
    "    '¤®ö': '^89.75 ',\n",
    "    '®¥õ': '^90.25 ',\n",
    "    '®¥ô': '^90.50 ',\n",
    "    '®¥ö': '^90.75 ',\n",
    "    '®¦õ': '^91.25 ',\n",
    "    '®¦ô': '^91.50 ',\n",
    "    '®¦ö': '^91.75 ',\n",
    "    '®§õ': '^92.25 ',\n",
    "    '®§ô': '^92.50 ',\n",
    "    '®§ö': '^92.75 ',\n",
    "    '® ̈õ': '^93.25 ',\n",
    "    '® ̈ô': '^93.50 ',\n",
    "    '® ̈ö': '^93.75 ',\n",
    "    '®©õ': '^94.25 ',\n",
    "    '®©ô': '^94.50 ',\n",
    "    '®©ö': '^94.75 ',\n",
    "    '®aõ': '^95.25 ',\n",
    "    '®aô': '^95.50 ',\n",
    "    '®aö': '^95.75 ',\n",
    "    '®«õ': '^96.25 ',\n",
    "    '®«ô': '^96.50 ',\n",
    "    '®«ö': '^96.75 ',\n",
    "    '®¬õ': '^97.25 ',\n",
    "    '®¬ô': '^97.50 ',\n",
    "    '®¬ö': '^97.75 ',\n",
    "    '®¤õ': '^98.25 ',\n",
    "    '®¤ô': '^98.50 ',\n",
    "    '®¤ö': '^98.75 ',\n",
    "    '®®õ': '^99.25 ',\n",
    "    '®®ô': '^99.50 ',\n",
    "    '®®ö': '^99.75 ',\n",
    "}\n",
    "\n",
    "map2 = {\n",
    "    \"¦õ\": \"^1.25 \",\n",
    "    \"¦ô\": \"^1.5 \",\n",
    "    \"¦ö\": \"^1.75 \",\n",
    "    \"§õ\": \"^2.25 \",\n",
    "    \"§ô\": \"^2.5 \",\n",
    "    \"§ö\": \"^2.75 \",\n",
    "    \" ̈õ\": \"^3.25 \",\n",
    "    \" ̈ô\": \"^3.5 \",\n",
    "    \" ̈ö\": \"^3.75 \",\n",
    "    \"©õ\": \"^4.25 \",\n",
    "    \"©ô\": \"^4.5 \",\n",
    "    \"©ö\": \"^4.75 \",\n",
    "    \"aõ\": \"^5.25 \",\n",
    "    \"aô\": \"^5.5 \",\n",
    "    \"aö\": \"^5.75 \",\n",
    "    \"«õ\": \"^6.25 \",\n",
    "    \"«ô\": \"^6.5 \",\n",
    "    \"«ö\": \"^6.75 \",\n",
    "    \"¬õ\": \"^7.25 \",\n",
    "    \"¬ô\": \"^7.5 \",\n",
    "    \"¬ö\": \"^7.75 \",\n",
    "    \"¤õ\": \"^8.25 \",\n",
    "    \"¤ô\": \"^8.5 \",\n",
    "    \"¤ö\": \"^8.75 \",\n",
    "    \"®õ\": \"^9.25 \",\n",
    "    \"®ô\": \"^9.5 \",\n",
    "    \"®ö\": \"^9.75 \",\n",
    "    \"¦¥\": \"^10 \",\n",
    "    \"¦¦\": \"^11 \",\n",
    "    \"¦§\": \"^12 \",\n",
    "    \"¦¨\": \"^13 \",\n",
    "    \"¦©\": \"^14 \",\n",
    "    \"¦a\": \"^15 \",\n",
    "    \"¦«\": \"^16 \",\n",
    "    \"¦¬\": \"^17 \",\n",
    "    \"¦¤­\": \"^18 \",\n",
    "    \"¦®\": \"^19 \",\n",
    "    \"§¥\": \"^20 \",\n",
    "    \"§¦\": \"^21 \",\n",
    "    \"§§\": \"^22 \",\n",
    "    \"§¨\": \"^23 \",\n",
    "    \"§©\": \"^24 \",\n",
    "    \"§a\": \"^25 \",\n",
    "    \"§«\": \"^26 \",\n",
    "    \"§¬\": \"^27 \",\n",
    "    \"§¤­\": \"^28 \",\n",
    "    \"§®\": \"^29 \",\n",
    "    \"¨¥\": \"^30 \",\n",
    "    \"¨¦\": \"^31 \",\n",
    "    \"¨§\": \"^32 \",\n",
    "    \"¨¨\": \"^33 \",\n",
    "    \"¨©\": \"^34 \",\n",
    "    \"¨a\": \"^35 \",\n",
    "    \"¨«\": \"^36 \",\n",
    "    \"¨¬\": \"^37 \",\n",
    "    \"¨¤­\": \"^38 \",\n",
    "    \"¨®\": \"^39 \",\n",
    "    \"©¥\": \"^40 \",\n",
    "    \"©¦\": \"^41 \",\n",
    "    \"©§\": \"^42 \",\n",
    "    \"©¨\": \"^43 \",\n",
    "    \"©©\": \"^44 \",\n",
    "    \"©a\": \"^45 \",\n",
    "    \"©«\": \"^46 \",\n",
    "    \"©¬\": \"^47 \",\n",
    "    \"©¤­\": \"^48 \",\n",
    "    \"©®\": \"^49 \",\n",
    "    \"a¥\": \"^50 \",\n",
    "    \"a¦\": \"^51 \",\n",
    "    \"a§\": \"^52 \",\n",
    "    \"a ̈ \": \"^53 \",\n",
    "    \"a©\": \"^54 \",\n",
    "    \"aa\": \"^55 \",\n",
    "    \"a«\": \"^56 \",\n",
    "    \"a¬\": \"^57 \",\n",
    "    \"a¤­\": \"^58 \",\n",
    "    \"a®\": \"^59 \",\n",
    "    \"«¥\": \"^60 \",\n",
    "    \"«¦\": \"^61 \",\n",
    "    \"«§\": \"^62 \",\n",
    "    \"«¨\": \"^63 \",\n",
    "    \"«©\": \"^64 \",\n",
    "    \"«a\": \"^65 \",\n",
    "    \"««\": \"^66 \",\n",
    "    \"«¬\": \"^67 \",\n",
    "    \"«¤­\": \"^68 \",\n",
    "    \"«®\": \"^69 \",\n",
    "    \"¬¥\": \"^70\",\n",
    "    \"¬¦\": \"^71 \",\n",
    "    \"¬§\": \"^72 \",\n",
    "    \"¬¨\": \"^73 \",\n",
    "    \"¬©\": \"^74 \",\n",
    "    \"¬a\": \"^75 \",\n",
    "    \"¬«\": \"^76 \",\n",
    "    \"¬¬\": \"^77 \",\n",
    "    \"¬¤­\": \"^78 \",\n",
    "    \"¬®\": \"^79 \",\n",
    "    \"¤¥\": \"^80 \",\n",
    "    \"¤­¦\": \"^81 \",\n",
    "    \"¤­§\": \"^82 \",\n",
    "    \"¤­¨\": \"^83 \",\n",
    "    \"¤­©\": \"^84 \",\n",
    "    \"¤­a\": \"^85 \",\n",
    "    \"¤­«\": \"^86 \",\n",
    "    \"¤­¬\": \"^87 \",\n",
    "    \"­¤¤­\": \"^88 \",\n",
    "    \"¤­®\": \"^89 \",\n",
    "    \"®¥\": \"^90 \",\n",
    "    \"®¦\": \"^91 \",\n",
    "    \"®§\": \"^92 \",\n",
    "    \"®¨\": \"^93 \",\n",
    "    \"®©\": \"^94 \",\n",
    "    \"®a\": \"^95 \",\n",
    "    \"®«\": \"^96 \",\n",
    "    \"®¬\": \"^97 \",\n",
    "    \"®¤­\": \"^98 \",\n",
    "    \"®®\": \"^99 \",\n",
    "}\n",
    "\n",
    "map1 = {\n",
    "\n",
    "    '¥': '^0 ',\n",
    "    'Â': '^0.0625',\n",
    "    '°': '^0.125',\n",
    "    'õ': '^0.25 ',\n",
    "    'ô': '^0.50 ',\n",
    "    'ö': '^0.75 ',\n",
    "    '¦': '^1 ',\n",
    "    '1±': '1^.1875 ',\n",
    "    '1o': '1^.375 ',\n",
    "    '§': '^2 ',\n",
    "    ' ̈ ': '^3 ',\n",
    "    ' Ë': '^3 ',\n",
    "    ' ̈1': '^3 1',\n",
    "    '©': '^4 ',\n",
    "    'a ': '^5 ',\n",
    "    '«': '^6 ',\n",
    "    '¬': '^7 ',\n",
    "    '¤': '^8 ',\n",
    "    '®': '^9 ',\n",
    "    \"Ç\": \"^(head) \",\n",
    "    \"É\": \"^(neck) \",\n",
    "    \"ó\": \"^(nose) \",\n",
    "        \n",
    "}\n",
    "\n",
    "map0 = {\n",
    "    \n",
    "    \"= \": \"=\",\n",
    "    \"¹\": \"^1\",\n",
    "    \"²\": \"^2\",\n",
    "    \"³\": \"^3\",\n",
    "    \"â\": \"Jan\",\n",
    "    \"á\": \"Feb\",\n",
    "    \"à\": \"Mar\",\n",
    "    \"ß\": \"Apr\",\n",
    "    \"Ü\": \"May\",\n",
    "    \"Þ\": \"June\",\n",
    "    \"Û\": \"July\",\n",
    "    \"Ý\": \"Aug\",\n",
    "    \"æ\": \"Sept\",\n",
    "    \"å\": \"Oct\",\n",
    "    \"ä\": \"Nov\",\n",
    "    \"ã\": \"Dec\",\n",
    "\n",
    "    \" fst\": \"fst\",\n",
    "    \" fm\": \"fm\",\n",
    "    \" gd\": \"gd\",\n",
    "    \" sly\": \"sly\",\n",
    "    \" my\": \"my\",\n",
    "    \" Í\": \"(star) \",\n",
    "\n",
    "    \" f\": \"f\",\n",
    "    \" C \": \"(C) \",\n",
    "    \" S \": \"(S) \",\n",
    "    \"ê\": \"(T)\",\n",
    "    \"ý\": \"(c) \",\n",
    "    \" ý\": \"(c) \",\n",
    "    \"ï\": \"(X)\",\n",
    "    \"ø\": \"^S\",\n",
    "    \"ÿ\": \"(s)\",\n",
    "    \" ÿ\": \"(s)\",\n",
    "    \"ú\": \"(A)\",\n",
    "\n",
    "    \"ç\": \"(fillie)\",\n",
    "    \"Î\": \"(older)\",\n",
    "    \"Md \": \"(Md)\",\n",
    "    \"Sp \": \"(Sp)\",\n",
    "    \"Wt \": \"(Wt)\",\n",
    "    \"Alw \": \"(Alw)\",\n",
    "    \"Clm \": \"(Clm)\",\n",
    "    \"OC \": \"(OC)\",\n",
    "    \"Ð\": \"(state)\",\n",
    "    \" N2X\": \"N2X\",\n",
    "    \" NC\": \"NC\",\n",
    "    \" N2L\": \"N2L\",\n",
    "    \" N3X\": \"N3X\",\n",
    "    \" NC\": \"NC\",\n",
    "    \" N3L\": \"N3L\",\n",
    "    \" N4X\": \"N4X\",\n",
    "    \" NC\": \"NC\",\n",
    "    \" N4L\": \"N4L\",\n",
    "    \" -N\": \"-N\",\n",
    "    \" B \": \"B \",\n",
    "    \n",
    "\n",
    "    \" /\": \"/\",\n",
    "    \"10/\": \" 10/\",\n",
    "    \"11/\": \" 11/\",\n",
    "    \"12/\": \" 12/\",\n",
    "    \"13/\": \" 13/\",\n",
    "    \"14/\": \" 14/\",\n",
    "    \"15/\": \" 15/\",\n",
    "    \"16/\": \" 16/\",\n",
    "    \"17/\": \" 17/\",\n",
    "    \"18/\": \" 18/\",\n",
    "        \n",
    "}\n",
    "\n",
    "mapC = {\n",
    "\n",
    "    \" C\\n\": \"(C) \",\n",
    "    \" (C) \": \"(C) \",\n",
    "    \" (X) \": \"(X) \",\n",
    "    \" (A) \": \"(A) \",\n",
    "    \" (T) \": \"(T) \",\n",
    "    \" (s) \": \"(s) \",\n",
    "    \" (c) \": \"(c) \",\n",
    "    \n",
    "    }\n",
    "\n",
    "raw_text = TXT_PATH.read_text(encoding=\"utf-8\", errors=\"ignore\")\n",
    "converted_text = convert_all_glyphs(raw_text, map3, map2, map1, map0, mapC)\n",
    "\n",
    "output_path = Path(\"C:\\\\Users\\\\tnaut\\\\horse_racing_calculator\\\\race_data\") / \"converted_data.txt\"\n",
    "output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "with output_path.open(\"w\", encoding=\"utf-8\", newline=\"\\n\") as f:\n",
    "    f.write(converted_text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76033de2",
   "metadata": {},
   "source": [
    "## Stitch together any split lines and create new TXT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b1ba65e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stitched history rows written to: race_data\\converted_data_combined.txt\n",
      "Tip: In your parsing cell, open OUT_TXT instead of IN_TXT.\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------\n",
    "# 0) PRE-COMBINE (STITCH) SPLIT HISTORY ROWS\n",
    "# ----------------------------\n",
    "\n",
    "# Update these paths to match your project\n",
    "DATA_DIR = Path(\"race_data\")  # or Path(\"data\") or whatever folder you use\n",
    "IN_TXT   = DATA_DIR / \"converted_data.txt\"\n",
    "OUT_TXT  = DATA_DIR / \"converted_data_combined.txt\"\n",
    "\n",
    "# --- Line classifiers ---\n",
    "RACE_HEADER_RE   = re.compile(r\"^\\s*Oaklawn\\s+Park\\b\", re.IGNORECASE)  # your \"new race\" signal\n",
    "HORSE_NUM_RE     = re.compile(r\"^\\s*\\S+\\s*$\")\n",
    "MORNINGLINE_RE   = re.compile(r\"^\\s*\\d+\\s*-\\s*\\d+\\s*$\")  # e.g., 6-1, 10-1\n",
    "HISTORY_START_RE = re.compile(r\"^\\s*[0-9A-Za-z]+=\")      # e.g., 14Dec25=...\n",
    "\n",
    "# Stop blocks that should never be appended onto a history line\n",
    "STOP_PREFIXES = (\n",
    "    \"WORKS:\", \"TRAINER:\", \"Previously trained\",\n",
    "    \"Claimedfrom\", \"Claimed from\",\n",
    "    \"Daily Racing Form\", \"OP, race\", \"--- Page\"\n",
    ")\n",
    "\n",
    "def is_race_header(line: str) -> bool:\n",
    "    return bool(RACE_HEADER_RE.match(line))\n",
    "\n",
    "def is_horse_header(lines, i: int) -> bool:\n",
    "    \"\"\"\n",
    "    Detects the 3-line horse header:\n",
    "      line i   : horse number (digits-only)\n",
    "      line i+1 : morning line (e.g., 6-1)\n",
    "      line i+2 : horse name (non-empty, not a label)\n",
    "    \"\"\"\n",
    "    if i + 2 >= len(lines):\n",
    "        return False\n",
    "    if not HORSE_NUM_RE.match(lines[i]):\n",
    "        return False\n",
    "    if not MORNINGLINE_RE.match(lines[i + 1]):\n",
    "        return False\n",
    "    name = lines[i + 2].strip()\n",
    "    if not name:\n",
    "        return False\n",
    "    # Avoid false positives\n",
    "    if name.startswith((\"Own:\", \"Tr:\", \"Timeform\", \"Post time\", \"Wagers:\", \"Beyer par\")):\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def should_stop_append(next_line: str, lines, j: int) -> bool:\n",
    "    \"\"\"\n",
    "    Stop conditions for joining lines onto a history record.\n",
    "    \"\"\"\n",
    "    s = next_line.strip()\n",
    "    if not s:\n",
    "        return False  # blank lines are ignored (not a stop)\n",
    "    if s.startswith(STOP_PREFIXES):\n",
    "        return True\n",
    "    if is_race_header(s):\n",
    "        return True\n",
    "    if is_horse_header(lines, j):\n",
    "        return True\n",
    "    if HISTORY_START_RE.match(s):  # next history record begins\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def stitch_history_rows(lines):\n",
    "    \"\"\"\n",
    "    For each line starting with date=, append subsequent lines until we reach\n",
    "    a clear boundary (next history, new horse, new race, WORKS/TRAINER/etc).\n",
    "    \"\"\"\n",
    "    stitched = []\n",
    "    i = 0\n",
    "    n = len(lines)\n",
    "\n",
    "    while i < n:\n",
    "        cur = lines[i].rstrip(\"\\n\")\n",
    "        cur_s = cur.strip()\n",
    "\n",
    "        if HISTORY_START_RE.match(cur_s):\n",
    "            buf = cur_s\n",
    "            j = i + 1\n",
    "\n",
    "            # Append continuation lines conservatively\n",
    "            while j < n and not should_stop_append(lines[j], lines, j):\n",
    "                nxt = lines[j].strip()\n",
    "                if nxt:  # ignore blanks\n",
    "                    buf += \" \" + nxt\n",
    "                j += 1\n",
    "\n",
    "            # Normalize internal whitespace for stability\n",
    "            buf = re.sub(r\"\\s+\", \" \", buf).strip()\n",
    "            stitched.append(buf)\n",
    "            i = j\n",
    "            continue\n",
    "\n",
    "        # Non-history lines: keep as-is (trim only trailing newline)\n",
    "        stitched.append(cur_s)\n",
    "        i += 1\n",
    "\n",
    "    return stitched\n",
    "\n",
    "# --- Run stitch + write output ---\n",
    "raw = IN_TXT.read_text(encoding=\"utf-8\", errors=\"ignore\").splitlines()\n",
    "combined_lines = stitch_history_rows(raw)\n",
    "\n",
    "OUT_TXT.parent.mkdir(parents=True, exist_ok=True)\n",
    "OUT_TXT.write_text(\"\\n\".join(combined_lines) + \"\\n\", encoding=\"utf-8\")\n",
    "\n",
    "print(f\"Stitched history rows written to: {OUT_TXT}\")\n",
    "print(\"Tip: In your parsing cell, open OUT_TXT instead of IN_TXT.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "e199f2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 1) Race + horse boundary detection (line-by-line safe)\n",
    "# ============================================================\n",
    "\n",
    "race_string = re.compile(r\"^\\s*Oaklawn\\s+Park\\b\", re.IGNORECASE)\n",
    "drf_footer  = re.compile(r\"^\\s*Daily\\s+Racing\\s+Form\\b\", re.IGNORECASE)\n",
    "\n",
    "horse_num_line     = re.compile(r\"^\\d+$\")\n",
    "morningline_string = re.compile(r\"^(\\d+)-(\\d+)$\")\n",
    "\n",
    "# ============================================================\n",
    "# 2) Horse-level single-line fields\n",
    "# ============================================================\n",
    "\n",
    "earlylate_string = re.compile(r\"Early\\s+(\\d+)\\s+Late(\\d+)\")\n",
    "jockey_string    = re.compile(r\"^(\\w+)\\(\\S+\\)\\S+:\\(\\S+\\)$\")\n",
    "trainer_string   = re.compile(r\"^Tr:\\s+(\\S+(?:\\s+\\w+)).*$\")\n",
    "dirtrec_string   = re.compile(r\"^D\\.Fst\\s+(\\d+)\\s+(\\d+)\")\n",
    "synthrec_string  = re.compile(r\"^Synth\\([^)]*\\)\\s+(\\d+)\\s+(\\d+)\")\n",
    "turfrec_string   = re.compile(r\"^Turf\\([^)]*\\)\\s+(\\d+)\\s+(\\d+)\")\n",
    "distance_string  = re.compile(r\"^Dst\\([^)]*\\)\\s+(\\d+)\\s+(\\d+)\")\n",
    "\n",
    "# ============================================================\n",
    "# 3) HISTORY REGEX — EXACTLY YOUR ORIGINAL PATTERN\n",
    "#    (no token parsing, no group reinterpretation)\n",
    "# ============================================================\n",
    "\n",
    "history_string = re.compile(\n",
    "    r\"^(?P<date>\\d{1,2}[A-Za-z]{1,}\\d{2})\"               # date\n",
    "    r\"=\\S+\\s+\"\n",
    "    r\"(?P<type>\\S+)\"                                     # type\n",
    "    r\".*\\:\\S+\\s+\"\n",
    "    r\"(?P<class>.*)\"                                    # class\n",
    "    r\"\\s+\"                \n",
    "    r\"(?P<beyer>\\S+)\"                                    # beyer\n",
    "    r\"\\s+\\d+\\/\\d+\\s+\"\n",
    "    r\"(?P<first_call>\\S+)\"                               # first call\n",
    "    r\"\\s+\\S+\\s+\\S+\\s+\\S+\\s+\"\n",
    "    r\"(?P<last_call>\\S+)\"                                # last call\n",
    "    r\".*$\"\n",
    ")\n",
    "\n",
    "# ============================================================\n",
    "# 4) Normalization helper\n",
    "# ============================================================\n",
    "\n",
    "def norm_line(line: str) -> str:\n",
    "    return (\n",
    "        line.replace(\"\\u2022\", \" \")\n",
    "            .replace(\"\\u00A0\", \" \")\n",
    "            .strip()\n",
    "    )\n",
    "\n",
    "# ============================================================\n",
    "# 5) DataFrame schema (wide history columns)\n",
    "# ============================================================\n",
    "\n",
    "MAX_HIST = 12\n",
    "\n",
    "HIST_FIELDS = [\n",
    "    \"date\",\n",
    "    \"type\",\n",
    "    \"class\",\n",
    "    \"beyer\",\n",
    "    \"first_call\",\n",
    "    \"last_call\",\n",
    "]\n",
    "\n",
    "columns = [\n",
    "    \"race_number\",\n",
    "    \"horse_number\",\n",
    "    \"horse_name\",\n",
    "    \"jockey\",\n",
    "    \"trainer\",\n",
    "    \"morning_line\",\n",
    "    \"early_speed\",\n",
    "    \"late_speed\",\n",
    "    \"dirt_starts\",\n",
    "    \"dirt_wins\",\n",
    "    \"synth_starts\",\n",
    "    \"synth_wins\",\n",
    "    \"turf_starts\",\n",
    "    \"turf_wins\",\n",
    "    \"distance_starts\",\n",
    "    \"distance_wins\",\n",
    "] + [\n",
    "    f\"hist{i}_{field}\"\n",
    "    for i in range(1, MAX_HIST + 1)\n",
    "    for field in HIST_FIELDS\n",
    "]\n",
    "\n",
    "# ============================================================\n",
    "# 6) Parsing logic\n",
    "# ============================================================\n",
    "\n",
    "race_number = 0\n",
    "rows = []\n",
    "current = None\n",
    "\n",
    "def init_history_slots(d: dict):\n",
    "    d[\"_hist_idx\"] = 1\n",
    "    for i in range(1, MAX_HIST + 1):\n",
    "        for field in HIST_FIELDS:\n",
    "            d[f\"hist{i}_{field}\"] = None\n",
    "\n",
    "def flush_current():\n",
    "    global current\n",
    "    if current and current.get(\"horse_number\") is not None:\n",
    "        current.pop(\"_hist_idx\", None)\n",
    "        rows.append(current)\n",
    "    current = None\n",
    "\n",
    "prev_prev = \"\"\n",
    "prev = \"\"\n",
    "\n",
    "with open(OUT_TXT, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
    "    for line_number, raw_line in enumerate(f, start=1):\n",
    "        line = norm_line(raw_line.rstrip(\"\\n\"))\n",
    "\n",
    "        # -------------------------\n",
    "        # RACE START\n",
    "        # -------------------------\n",
    "        if race_string.search(line) and not drf_footer.search(line):\n",
    "            race_number += 1\n",
    "            flush_current()\n",
    "            prev_prev, prev = prev, line\n",
    "            continue\n",
    "\n",
    "        # -------------------------\n",
    "        # HORSE START (num → odds → name)\n",
    "        # -------------------------\n",
    "        if horse_num_line.fullmatch(prev_prev) and morningline_string.fullmatch(prev) and line:\n",
    "            flush_current()\n",
    "\n",
    "            ml = morningline_string.fullmatch(prev)\n",
    "\n",
    "            current = {\n",
    "                \"race_number\": race_number,\n",
    "                \"horse_number\": int(prev_prev),\n",
    "                \"horse_name\": line,\n",
    "                \"jockey\": None,\n",
    "                \"trainer\": None,\n",
    "                \"morning_line\": f\"{ml.group(1)}-{ml.group(2)}\",\n",
    "                \"early_speed\": None,\n",
    "                \"late_speed\": None,\n",
    "                \"dirt_starts\": None,\n",
    "                \"dirt_wins\": None,\n",
    "                \"synth_starts\": None,\n",
    "                \"synth_wins\": None,\n",
    "                \"turf_starts\": None,\n",
    "                \"turf_wins\": None,\n",
    "                \"distance_starts\": None,\n",
    "                \"distance_wins\": None,\n",
    "            }\n",
    "\n",
    "            init_history_slots(current)\n",
    "            prev_prev, prev = prev, line\n",
    "            continue\n",
    "\n",
    "        # -------------------------\n",
    "        # FIELD EXTRACTION (inside horse)\n",
    "        # -------------------------\n",
    "        if current is not None and line:\n",
    "\n",
    "            m = earlylate_string.search(line)\n",
    "            if m:\n",
    "                current[\"early_speed\"] = int(m.group(1))\n",
    "                current[\"late_speed\"] = int(m.group(2))\n",
    "\n",
    "            m = jockey_string.search(line)\n",
    "            if m:\n",
    "                current[\"jockey\"] = m.group(1).strip()\n",
    "\n",
    "            m = trainer_string.search(line)\n",
    "            if m:\n",
    "                current[\"trainer\"] = m.group(1).strip()\n",
    "\n",
    "            m = dirtrec_string.search(line)\n",
    "            if m:\n",
    "                current[\"dirt_starts\"] = int(m.group(1))\n",
    "                current[\"dirt_wins\"] = int(m.group(2))\n",
    "\n",
    "            m = synthrec_string.search(line)\n",
    "            if m:\n",
    "                current[\"synth_starts\"] = int(m.group(1))\n",
    "                current[\"synth_wins\"] = int(m.group(2))\n",
    "\n",
    "            m = turfrec_string.search(line)\n",
    "            if m:\n",
    "                current[\"turf_starts\"] = int(m.group(1))\n",
    "                current[\"turf_wins\"] = int(m.group(2))\n",
    "\n",
    "            m = distance_string.search(line)\n",
    "            if m:\n",
    "                current[\"distance_starts\"] = int(m.group(1))\n",
    "                current[\"distance_wins\"] = int(m.group(2))\n",
    "\n",
    "            # -------------------------\n",
    "            # HISTORY (single-regex capture)\n",
    "            # -------------------------\n",
    "            m = history_string.search(line)\n",
    "            if m:\n",
    "                idx = current[\"_hist_idx\"]\n",
    "                if idx <= MAX_HIST:\n",
    "                    current[f\"hist{idx}_date\"]        = m.group(\"date\")\n",
    "                    current[f\"hist{idx}_type\"]        = m.group(\"type\")\n",
    "                    current[f\"hist{idx}_class\"]       = m.group(\"class\")\n",
    "                    current[f\"hist{idx}_beyer\"]       = m.group(\"beyer\")\n",
    "                    current[f\"hist{idx}_first_call\"]  = m.group(\"first_call\")\n",
    "                    current[f\"hist{idx}_last_call\"]   = m.group(\"last_call\")\n",
    "                    current[\"_hist_idx\"] = idx + 1\n",
    "\n",
    "        prev_prev, prev = prev, line\n",
    "\n",
    "# Flush last horse\n",
    "flush_current()\n",
    "\n",
    "df = pd.DataFrame(rows, columns=columns)\n",
    "\n",
    "df.to_csv(\"C:\\\\Users\\\\tnaut\\\\horse_racing_calculator\\\\race_data\\\\output.csv\", index=False)\n",
    "\n",
    "df.to_excel(\"C:\\\\Users\\\\tnaut\\\\horse_racing_calculator\\\\race_data\\\\output.xlsx\", index=False)\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xarray-climate",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
